{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import xarray as xr\n",
    "import urllib.request\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate data\n",
    "data_location = \"/Users/kris/amazonforcast/data/202301/LIS_HIST_2023_Jan.nc\"\n",
    "ds = xr.open_dataset(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = ds['Evap_tavg'].isel(time = 0)\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and read the geojson file for Italys regions. \n",
    "hydrobasins_lev05_url = \"https://raw.githubusercontent.com/blackteacatsu/spring_2024_envs_research_amazon_ldas/main/resources/hybas_sa_lev05_areaofstudy.geojson\"\n",
    "with urllib.request.urlopen(hydrobasins_lev05_url) as url:\n",
    "        jdata = json.loads(url.read().decode())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mixing dicts with non-Series may lead to ambiguous ordering.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(jdata)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\geopandas\\geodataframe.py:151\u001b[0m, in \u001b[0;36mGeoDataFrame.__init__\u001b[1;34m(self, data, geometry, crs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, DataFrame)\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, GeoDataFrame)\n\u001b[0;32m    149\u001b[0m ):\n\u001b[0;32m    150\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# set_geometry ensures the geometry data have the proper dtype,\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# but is not called if `geometry=None` ('geometry' column present\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# in the data), so therefore need to ensure it here manually\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# if gdf passed in and geo_col is set, we use that for geometry\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, GeoDataFrame):\n",
      "File \u001b[1;32mc:\\Users\\Kris\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\Kris\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Kris\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Kris\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:680\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n",
      "\u001b[1;31mValueError\u001b[0m: Mixing dicts with non-Series may lead to ambiguous ordering."
     ]
    }
   ],
   "source": [
    "gpd.GeoDataFrame(jdata).set_geometry('coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfaf_id = []\n",
    "for region in jdata['features']:\n",
    "    pfaf_id.append(region['properties']['PFAF_ID'])\n",
    "\n",
    "for region in jdata['features']:\n",
    "    if region['geometry']['type'] == 'Polygon':\n",
    "        for p in region[\"geometry\"][\"coordinates\"][0]:\n",
    "            print(p[0])\n",
    "\n",
    "for region in jdata['features']:\n",
    "    if region['geometry']['type'] == 'MultiPolygon':\n",
    "        #print(\"feature is a multipolygon\")\n",
    "        for polyg in region[\"geometry\"][\"coordinates\"]:\n",
    "            for p in polyg[0]:\n",
    "                print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            **{\n",
    "                \"x\": [p[0] for p in region[\"geometry\"][\"coordinates\"][0]],\n",
    "                \"y\": [p[1] for p in region[\"geometry\"][\"coordinates\"][0]],\n",
    "                \"fill\": \"toself\",\n",
    "                \"name\": region['properties']['PFAF_ID'],\n",
    "            }\n",
    "        )\n",
    "        for region in jdata[\"features\"] if region['geometry']['type'] == 'Polygon' \n",
    "    ]+\n",
    "\n",
    "    ## Add multipolygon to the graph\n",
    "    [\n",
    "        go.Scatter(\n",
    "            x=[p[0] for p in polyg[0]],\n",
    "            y=[p[1] for p in polyg[0]],\n",
    "            fill=\"toself\",\n",
    "            name=region['properties']['PFAF_ID'],\n",
    "        )\n",
    "        for region in jdata[\"features\"] if region['geometry']['type'] == 'MultiPolygon'\n",
    "        for polyg in region[\"geometry\"][\"coordinates\"]\n",
    "    ]\n",
    ").update_layout(width=1000, height=900, showlegend=False, margin={\"l\":0,\"r\":0,\"t\":0,\"b\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Loop through the geojson features\n",
    "for region in jdata[\"features\"]:\n",
    "    # Handle Polygons\n",
    "    if region['geometry']['type'] == 'Polygon':\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[p[0] for p in region[\"geometry\"][\"coordinates\"][0]],\n",
    "            y=[p[1] for p in region[\"geometry\"][\"coordinates\"][0]],\n",
    "            fill=\"toself\",\n",
    "            name=region['properties']['PFAF_ID'],\n",
    "            line=dict(width=1, color='orange'),\n",
    "            showlegend=False,\n",
    "        ))\n",
    "    \n",
    "    # Handle MultiPolygons\n",
    "    elif region['geometry']['type'] == 'MultiPolygon':\n",
    "        for polyg in region['geometry']['coordinates']:\n",
    "            # Unpack each polygon and ensure separation with None\n",
    "            x_coords = [point[0] for point in polyg[0]] + [None]\n",
    "            y_coords = [point[1] for point in polyg[0]] + [None]\n",
    "            \n",
    "            # Add as a new scatter trace\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_coords,\n",
    "                y=y_coords,\n",
    "                fill=\"toself\",\n",
    "                name=region['properties']['PFAF_ID'],\n",
    "                line=dict(width=1, color='orange'),\n",
    "                showlegend=False,\n",
    "            ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=1000, \n",
    "    height=900, \n",
    "    showlegend=False, \n",
    "    margin={\"l\": 0, \"r\": 0, \"t\": 0, \"b\": 0}\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = []#list of points defining boundaries of polygons\n",
    "for feature in jdata['features']:\n",
    "    if feature['geometry']['type'] == 'Polygon':\n",
    "        pts.extend(feature['geometry']['coordinates'][0])    \n",
    "        pts.append([None, None])#mark the end of a polygon   \n",
    "        \n",
    "    elif feature['geometry']['type'] == 'MultiPolygon':\n",
    "        for polyg in feature['geometry']['coordinates']:\n",
    "            pts.extend(polyg[0])\n",
    "            pts.append([None, None])#end of polygon\n",
    "    else: pass           \n",
    "    #else: raise ValueError(\"geometry type irrelevant for map\")\n",
    "\n",
    "x, y = zip(*pts) \n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(x=x, y=y, mode='lines', line_color='#121212', line_width=1.5, fill='toself')\n",
    "#fig.add_heatmap(z=selected_data.values, x=selected_data['east_west'], y=selected_data['north_south'])\n",
    "fig.update_layout(width=1000,  height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = go.Figure()\n",
    "figure.update_layout(width=1000,  height=900)\n",
    "figure.add_heatmap(z=selected_data.values, x=selected_data['east_west'], y=selected_data['north_south'], showlegend=False)\n",
    "for feature in jdata['features']:\n",
    "    pts = []\n",
    "    if feature['geometry']['type'] == 'Polygon':\n",
    "        pts.extend(feature['geometry']['coordinates'][0])    \n",
    "        pts.append([None, None])#mark the end of a polygon   \n",
    "        \n",
    "    elif feature['geometry']['type'] == 'MultiPolygon':\n",
    "        for polyg in feature['geometry']['coordinates']:\n",
    "            pts.extend(polyg[0])\n",
    "            pts.append([None, None])#end of polygon\n",
    "    elif feature['geometry']['type'] == 'LineString': \n",
    "        points.extend(feature['geometry']['coordinates'])\n",
    "        points.append([None, None])\n",
    "    else: pass           \n",
    "    #else: raise ValueError(\"geometry type irrelevant for map\")\n",
    "    x, y = zip(*pts)\n",
    "    figure.add_scatter(x=x, y=y, mode='lines', line_color='#121212', line_width=1.5, showlegend=False)\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Iterate through features and create scatter traces for each polygon and multipolygon\n",
    "for feature in jdata['features']:\n",
    "    # Extract the PFAF_ID for hover labels\n",
    "    pfaf_id = feature['properties']['PFAF_ID']\n",
    "    \n",
    "    # Handle Polygon type\n",
    "    if feature['geometry']['type'] == 'Polygon':\n",
    "        # Collect points\n",
    "        x, y = zip(*feature['geometry']['coordinates'][0])\n",
    "        # Add scatter trace with hover text\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode='lines',\n",
    "            line=dict(color='#121212', width=1.5),\n",
    "            fill='toself',\n",
    "            text=feature['properties']['PFAF_ID'],  # Add PFAF_ID for each point\n",
    "            hoverinfo='text'  # Show only the PFAF_ID as hover text\n",
    "        ))\n",
    "        # Add None to separate polygons if needed\n",
    "\n",
    "    # Handle MultiPolygon type\n",
    "    elif feature['geometry']['type'] == 'MultiPolygon':\n",
    "        for polyg in feature['geometry']['coordinates']:\n",
    "            x, y = zip(*polyg[0])\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                mode='lines',\n",
    "                line=dict(color='#121212', width=1.5),\n",
    "                fill='toself',\n",
    "                text=feature['properties']['PFAF_ID'],  # Add PFAF_ID for each point\n",
    "                hoverinfo='text'\n",
    "            ))\n",
    "\n",
    "# Update layout settings\n",
    "fig.update_layout(\n",
    "    width=1000, \n",
    "    height=900,\n",
    "    showlegend=False, \n",
    "    margin={\"l\": 0, \"r\": 0, \"t\": 0, \"b\": 0}\n",
    ")\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
